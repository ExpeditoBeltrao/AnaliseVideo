{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPDz945RB8xjCicd1RcGOAS"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"OAY02gwdadXK","executionInfo":{"status":"ok","timestamp":1753659081209,"user_tz":180,"elapsed":47819,"user":{"displayName":"Expedito Beltrao","userId":"00020342427364133603"}},"outputId":"6a42ecd0-9efd-42f7-976f-5b1174fc513a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: deepface in /usr/local/lib/python3.11/dist-packages (0.0.93)\n","Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.11/dist-packages (4.12.0.88)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n","Requirement already satisfied: mediapipe in /usr/local/lib/python3.11/dist-packages (0.10.14)\n","Requirement already satisfied: requests>=2.27.1 in /usr/local/lib/python3.11/dist-packages (from deepface) (2.32.4)\n","Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from deepface) (1.24.3)\n","Requirement already satisfied: pandas>=0.23.4 in /usr/local/lib/python3.11/dist-packages (from deepface) (2.2.2)\n","Requirement already satisfied: gdown>=3.10.1 in /usr/local/lib/python3.11/dist-packages (from deepface) (5.2.0)\n","Requirement already satisfied: Pillow>=5.2.0 in /usr/local/lib/python3.11/dist-packages (from deepface) (11.3.0)\n","Requirement already satisfied: opencv-python>=4.5.5.64 in /usr/local/lib/python3.11/dist-packages (from deepface) (4.12.0.88)\n","Requirement already satisfied: tensorflow>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from deepface) (2.13.0)\n","Requirement already satisfied: keras>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from deepface) (2.13.1)\n","Requirement already satisfied: Flask>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from deepface) (3.1.1)\n","Requirement already satisfied: flask-cors>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from deepface) (6.0.1)\n","Requirement already satisfied: mtcnn>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from deepface) (1.0.0)\n","Requirement already satisfied: retina-face>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from deepface) (0.0.17)\n","Requirement already satisfied: fire>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from deepface) (0.7.0)\n","Requirement already satisfied: gunicorn>=20.1.0 in /usr/local/lib/python3.11/dist-packages (from deepface) (23.0.0)\n","Collecting numpy>=1.14.0 (from deepface)\n","  Using cached numpy-2.2.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.59.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (25.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from mediapipe) (2.3.1)\n","Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (25.3.0)\n","Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (25.2.10)\n","Requirement already satisfied: jax in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.5.2)\n","Requirement already satisfied: jaxlib in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.5.1)\n","Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.11/dist-packages (from mediapipe) (4.11.0.86)\n","Requirement already satisfied: protobuf<5,>=4.25.3 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (4.25.8)\n","Requirement already satisfied: sounddevice>=0.4.4 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.5.2)\n","Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from fire>=0.4.0->deepface) (3.1.0)\n","Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from Flask>=1.1.2->deepface) (1.9.0)\n","Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from Flask>=1.1.2->deepface) (8.2.1)\n","Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from Flask>=1.1.2->deepface) (2.2.0)\n","Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from Flask>=1.1.2->deepface) (3.1.6)\n","Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from Flask>=1.1.2->deepface) (3.0.2)\n","Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from Flask>=1.1.2->deepface) (3.1.3)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown>=3.10.1->deepface) (4.13.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown>=3.10.1->deepface) (3.18.0)\n","Requirement already satisfied: joblib>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from mtcnn>=0.1.0->deepface) (1.5.1)\n","Requirement already satisfied: lz4>=4.3.3 in /usr/local/lib/python3.11/dist-packages (from mtcnn>=0.1.0->deepface) (4.4.4)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.23.4->deepface) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.23.4->deepface) (2025.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.27.1->deepface) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.27.1->deepface) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.27.1->deepface) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.27.1->deepface) (2025.7.14)\n","Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.11/dist-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (1.6.3)\n","Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (0.4.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (0.2.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (1.74.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (3.14.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (18.1.1)\n","INFO: pip is looking at multiple versions of tensorflow to determine which version is compatible with other requirements. This could take a while.\n","Collecting tensorflow>=1.9.0 (from deepface)\n","  Downloading tensorflow-2.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (3.4.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (80.9.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (4.5.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (1.17.2)\n","Collecting tensorboard~=2.19.0 (from tensorflow>=1.9.0->deepface)\n","  Downloading tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n","Collecting keras>=2.2.0 (from deepface)\n","  Downloading keras-3.10.0-py3-none-any.whl.metadata (6.0 kB)\n","Collecting numpy>=1.14.0 (from deepface)\n","  Downloading numpy-2.1.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting ml-dtypes<1.0.0,>=0.5.1 (from tensorflow>=1.9.0->deepface)\n","  Downloading ml_dtypes-0.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (0.37.1)\n","Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=2.2.0->deepface) (13.9.4)\n","Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=2.2.0->deepface) (0.1.0)\n","Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=2.2.0->deepface) (0.16.0)\n","Requirement already satisfied: scipy>=1.11.1 in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (1.16.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow>=1.9.0->deepface) (0.45.1)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow>=1.9.0->deepface) (3.8.2)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow>=1.9.0->deepface) (0.7.2)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown>=3.10.1->deepface) (2.7)\n","Collecting typing-extensions>=3.6.6 (from tensorflow>=1.9.0->deepface)\n","  Downloading typing_extensions-4.14.1-py3-none-any.whl.metadata (3.0 kB)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown>=3.10.1->deepface) (1.7.1)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=2.2.0->deepface) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=2.2.0->deepface) (2.19.2)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=2.2.0->deepface) (0.1.2)\n","Downloading tensorflow-2.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (644.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m644.9/644.9 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading keras-3.10.0-py3-none-any.whl (1.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m68.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading numpy-2.1.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m101.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading ml_dtypes-0.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m126.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m80.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading typing_extensions-4.14.1-py3-none-any.whl (43 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.9/43.9 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: typing-extensions, numpy, tensorboard, ml-dtypes, keras, tensorflow\n","  Attempting uninstall: typing-extensions\n","    Found existing installation: typing_extensions 4.5.0\n","    Uninstalling typing_extensions-4.5.0:\n","      Successfully uninstalled typing_extensions-4.5.0\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.24.3\n","    Uninstalling numpy-1.24.3:\n","      Successfully uninstalled numpy-1.24.3\n","  Attempting uninstall: tensorboard\n","    Found existing installation: tensorboard 2.13.0\n","    Uninstalling tensorboard-2.13.0:\n","      Successfully uninstalled tensorboard-2.13.0\n","  Attempting uninstall: ml-dtypes\n","    Found existing installation: ml-dtypes 0.4.1\n","    Uninstalling ml-dtypes-0.4.1:\n","      Successfully uninstalled ml-dtypes-0.4.1\n","  Attempting uninstall: keras\n","    Found existing installation: keras 2.13.1\n","    Uninstalling keras-2.13.1:\n","      Successfully uninstalled keras-2.13.1\n","  Attempting uninstall: tensorflow\n","    Found existing installation: tensorflow 2.13.0\n","    Uninstalling tensorflow-2.13.0:\n","      Successfully uninstalled tensorflow-2.13.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n","torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\n","tf-keras 2.18.0 requires tensorflow<2.19,>=2.18, but you have tensorflow 2.19.0 which is incompatible.\n","tensorflow-decision-forests 1.11.0 requires tensorflow==2.18.0, but you have tensorflow 2.19.0 which is incompatible.\n","numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.1.3 which is incompatible.\n","ydf 0.13.0 requires protobuf<7.0.0,>=5.29.1, but you have protobuf 4.25.8 which is incompatible.\n","tensorflow-text 2.18.1 requires tensorflow<2.19,>=2.18.0, but you have tensorflow 2.19.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed keras-3.10.0 ml-dtypes-0.5.1 numpy-2.1.3 tensorboard-2.19.0 tensorflow-2.19.0 typing-extensions-4.14.1\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["numpy"]},"id":"0d342570aeca4511bb4e82b8ce1069da"}},"metadata":{}}],"source":["!pip install deepface opencv-python-headless tqdm matplotlib mediapipe"]},{"cell_type":"code","source":["# Importa o DeepFace para análise de emoções faciais\n","from deepface import DeepFace\n","\n","# OpenCV para leitura e escrita de vídeo, além de manipulação de imagem\n","import cv2\n","\n","# tqdm para barra de progresso durante o processamento do vídeo\n","from tqdm import tqdm\n","\n","# Counter e deque para contagem de eventos e armazenamento histórico com tamanho fixo\n","from collections import Counter, deque\n","\n","# MediaPipe para extração de pontos do corpo (pose)\n","import mediapipe as mp\n","\n","# json para salvar o relatório final com estatísticas\n","import json\n","\n","# Caminhos para o vídeo de entrada e saída\n","input_video_path = './Video1.mp4'\n","output_video_path = './Saida_Video1.mp4'\n","\n","# Inicialização do MediaPipe Pose\n","mp_pose = mp.solutions.pose\n","pose = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5)\n","\n","# Filas circulares para armazenar histórico recente de movimentos (aceno e dança)\n","hand_wave_history = deque(maxlen=5)\n","dancing_history = deque(maxlen=5)\n","\n","# Função principal para classificar a atividade corporal com base nos landmarks da pose\n","def classify_activity(pose_landmarks):\n","    if not pose_landmarks:\n","        return \"desconhecida\"  # Nenhum ponto de corpo detectado\n","\n","    # Verifica se um landmark é visível com confiança (> 0.5)\n","    def is_visible(lm): return lm and lm.visibility > 0.5\n","\n","    lm = pose_landmarks.landmark\n","\n","    # Retorna o landmark com segurança (caso não exista ou dê erro)\n","    def get_safe(name):\n","        try:\n","            return lm[mp_pose.PoseLandmark[name]]\n","        except:\n","            return None\n","\n","    # Coleta os principais pontos do corpo\n","    l_sh = get_safe(\"LEFT_SHOULDER\")\n","    r_sh = get_safe(\"RIGHT_SHOULDER\")\n","    l_hp = get_safe(\"LEFT_HIP\")\n","    r_hp = get_safe(\"RIGHT_HIP\")\n","    l_kn = get_safe(\"LEFT_KNEE\")\n","    r_kn = get_safe(\"RIGHT_KNEE\")\n","    l_wr = get_safe(\"LEFT_WRIST\")\n","    r_wr = get_safe(\"RIGHT_WRIST\")\n","    l_an = get_safe(\"LEFT_ANKLE\")\n","    r_an = get_safe(\"RIGHT_ANKLE\")\n","    r_eye = get_safe(\"RIGHT_EYE\")\n","    l_eye = get_safe(\"LEFT_EYE\")\n","    r_elbow = get_safe(\"RIGHT_ELBOW\")\n","    l_elbow = get_safe(\"LEFT_ELBOW\")\n","\n","    # 1. Detecta se a pessoa está deitada\n","    if is_visible(r_eye) and is_visible(r_sh) and is_visible(l_eye):\n","        if (r_sh.y < r_eye.y) and (r_eye.y < l_eye.y):\n","            return \"deitado\"\n","\n","    # 2. Detecta aceno (com a mão esquerda visível e direita não visível, acima do ombro)\n","    if not is_visible(r_wr) and is_visible(l_wr) and is_visible(l_sh):\n","        is_waving = l_wr.y < l_sh.y\n","        hand_wave_history.append(is_waving)\n","        if hand_wave_history.count(True) >= 3:\n","            return \"acenando\"\n","\n","    # 3. Detecta dança (mãos visíveis, mão esquerda acima do ombro por repetição)\n","    if is_visible(r_wr) and is_visible(l_wr) and is_visible(l_sh):\n","        is_dancing = l_wr.y < l_sh.y\n","        dancing_history.append(is_dancing)\n","        if dancing_history.count(True) >= 3:\n","            return \"dancando\"\n","\n","    # 4. Detecta se a pessoa está de perfil (com base na posição do ombro e profundidade)\n","    if is_visible(r_sh):\n","        if (r_wr.x > r_elbow.x) or (r_sh.z < l_sh.z):\n","            return \"perfil\"\n","\n","    # 5. Detecta se a pessoa está com os olhos visíveis — pode indicar careta ou sorriso\n","    if is_visible(r_eye) and is_visible(l_eye):\n","        return \"sorriso/careta\"\n","\n","    return \"desconhecida\"\n","\n","# Função principal que processa o vídeo e classifica emoções + atividades\n","def detect_emotions(video_path, output_path, resize_factor=0.5, frame_skip=3):\n","    cap = cv2.VideoCapture(video_path)\n","    if not cap.isOpened():\n","        print(\"Erro ao abrir o vídeo.\")\n","        return\n","\n","    # Extrai metadados do vídeo\n","    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n","    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n","    fps = int(cap.get(cv2.CAP_PROP_FPS)) or 30\n","    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n","    frame_size = (int(width * resize_factor), int(height * resize_factor))\n","    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n","    out = cv2.VideoWriter(output_path, fourcc, fps, frame_size)\n","\n","    # Contadores e armazenamento de histórico\n","    emotion_counter = Counter()\n","    activity_counter = Counter()\n","    unknown_activity_count = 0\n","    analyzed_frame_count = 0\n","\n","    frame_index = 0\n","    face_emotion_history = {}  # Histórico de emoções por face detectada\n","    previous_emotion = {}      # Última emoção detectada (para suavização)\n","\n","    # Loop principal de processamento de cada frame\n","    for _ in tqdm(range(total_frames), desc=\"Processando vídeo\"):\n","        ret, frame = cap.read()\n","        if not ret:\n","            break\n","\n","        # Redimensiona o frame, se necessário\n","        if resize_factor != 1.0:\n","            frame = cv2.resize(frame, frame_size)\n","\n","        frame_index += 1\n","        if frame_index % frame_skip != 0:\n","            out.write(frame)\n","            continue\n","\n","        # Converte para RGB para o MediaPipe\n","        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n","        results_pose = pose.process(rgb_frame)\n","\n","        # Classificação da atividade corporal\n","        # Estou classificando a atividade corporal da pessoa mais proeminente no\n","        # frame. Media Pipe Pose no modo single-person.\n","        atividade = classify_activity(results_pose.pose_landmarks)\n","        analyzed_frame_count += 1\n","        activity_counter[atividade] += 1\n","        if atividade == \"desconhecida\":\n","            unknown_activity_count += 1\n","\n","        # Análise de emoções com DeepFace. Tentei utilizar o \"opencv\" mas não\n","        # detectava rostos laterais. Mais rápido e leve.\n","        # O algorítimo \"retinaface\" é mais robusto e preciso. Execução pesada.\n","        # Explorei resize_factor=0.5, reduzindo o tamanho do frame analisado e\n","        # também ajuste o frame_skip, reduzindo a quantidade de frames analisados.\n","        # Testei com 10, 5 e 3. No total o vídeo analisado possui 3326 frames.\n","        # Só ganhei performance na análise quando passei a utilizar a GPU T4 -\n","        # NVIDIA Tesla T4 - no Colabs.\n","\n","        try:\n","            result = DeepFace.analyze(\n","                frame,\n","                actions=['emotion'],\n","                enforce_detection=False,\n","                detector_backend='retinaface'\n","            )\n","        except Exception as e:\n","            print(f\"[Frame {frame_index}] Erro ao analisar: {e}\")\n","            out.write(frame)\n","            continue\n","\n","        # Processa cada rosto detectado\n","        if isinstance(result, list) and result:\n","            for face in result:\n","                try:\n","                    region = face.get('region', {})\n","                    x = max(0, region.get('x', 0))\n","                    y = max(0, region.get('y', 0))\n","                    w = min(region.get('w', 0), frame.shape[1] - x)\n","                    h = min(region.get('h', 0), frame.shape[0] - y)\n","\n","                    dominant_emotion = face.get('dominant_emotion', None)\n","                    if dominant_emotion:\n","                        emotion_counter[dominant_emotion] += 1\n","\n","                    # Percepções iniciais sobre a detecção das emoções:\n","                    # As emoções estavam oscilando muito frame a frame devido a\n","                    # pequenas variações de iluminação, ângulo ou ruído. O vídeo\n","                    # final apresentou um resultado visual confuso e inconstante.\n","\n","                    # Utilizei a técnica de suavização de emoção, assim, a emoção\n","                    # exibida na tela é mais estável, coerente e agradável ao usuário.\n","\n","                    # Histórico da face (usando coordenadas como ID simplificado)\n","                    face_id = (x, y, w, h)\n","                    if face_id not in face_emotion_history:\n","                        face_emotion_history[face_id] = deque(maxlen=10)\n","\n","                    face_emotion_history[face_id].append(dominant_emotion)\n","\n","                    # Suavização de emoção (filtra oscilações)\n","                    emotion_freq = Counter(face_emotion_history[face_id])\n","                    most_common_emotion, count = emotion_freq.most_common(1)[0]\n","                    smoothed_emotion = most_common_emotion if count >= 5 else previous_emotion.get(face_id, most_common_emotion)\n","                    previous_emotion[face_id] = smoothed_emotion\n","\n","                    # Desenha retângulo e texto com emoção e atividade\n","                    cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n","                    text_y = y - 10 if y - 10 > 20 else y + h + 20\n","                    cv2.putText(frame, smoothed_emotion, (x, text_y),\n","                                cv2.FONT_HERSHEY_SIMPLEX, 0.9, (36, 255, 12), 2)\n","                    cv2.putText(frame, atividade, (x, text_y + 25),\n","                                cv2.FONT_HERSHEY_SIMPLEX, 0.8, (36, 255, 12), 2)\n","                except Exception as e:\n","                    print(f\"Erro ao processar face: {e}\")\n","                    continue\n","\n","        out.write(frame)\n","\n","    cap.release()\n","    out.release()\n","\n","    # Gera e salva relatório final em JSON\n","    report = {\n","        \"Total de frames analisados\": analyzed_frame_count,\n","        \"Total de anomalias (atividade 'desconhecida')\": unknown_activity_count,\n","        \"Distribuição de emoções\": dict(emotion_counter),\n","        \"Distribuição de atividades\": dict(activity_counter)\n","    }\n","\n","    with open(\"relatorio_analise_video.json\", \"w\", encoding=\"utf-8\") as f:\n","        json.dump(report, f, indent=4, ensure_ascii=False)\n","\n","    print(\"Relatório salvo em: relatorio_analise_video.json\")\n","\n","\n","# Inicia o processamento do vídeo\n","detect_emotions(input_video_path, output_video_path)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fFE122F6bU4P","executionInfo":{"status":"ok","timestamp":1753659581396,"user_tz":180,"elapsed":405518,"user":{"displayName":"Expedito Beltrao","userId":"00020342427364133603"}},"outputId":"147ce33c-32f4-413b-c726-4efae8f413e4"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stderr","text":["\rProcessando vídeo:   0%|          | 0/3326 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["25-07-27 23:32:59 - retinaface.h5 will be downloaded from the url https://github.com/serengil/deepface_models/releases/download/v1.0/retinaface.h5\n"]},{"output_type":"stream","name":"stderr","text":["Downloading...\n","From: https://github.com/serengil/deepface_models/releases/download/v1.0/retinaface.h5\n","To: /root/.deepface/weights/retinaface.h5\n","\n","  0%|          | 0.00/119M [00:00<?, ?B/s]\u001b[A\n","  9%|▉         | 11.0M/119M [00:00<00:02, 39.3MB/s]\u001b[A\n"," 18%|█▊        | 21.5M/119M [00:00<00:02, 40.1MB/s]\u001b[A\n"," 27%|██▋       | 32.0M/119M [00:00<00:02, 40.0MB/s]\u001b[A\n"," 36%|███▌      | 42.5M/119M [00:01<00:01, 40.4MB/s]\u001b[A\n"," 45%|████▍     | 53.0M/119M [00:01<00:01, 41.3MB/s]\u001b[A\n"," 53%|█████▎    | 63.4M/119M [00:01<00:01, 41.6MB/s]\u001b[A\n"," 62%|██████▏   | 73.9M/119M [00:01<00:01, 41.1MB/s]\u001b[A\n"," 71%|███████   | 84.4M/119M [00:02<00:00, 41.8MB/s]\u001b[A\n"," 80%|███████▉  | 94.9M/119M [00:02<00:00, 41.2MB/s]\u001b[A\n"," 89%|████████▉ | 105M/119M [00:02<00:00, 40.1MB/s] \u001b[A\n","100%|██████████| 119M/119M [00:02<00:00, 41.2MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["25-07-27 23:33:09 - facial_expression_model_weights.h5 will be downloaded...\n"]},{"output_type":"stream","name":"stderr","text":["Downloading...\n","From: https://github.com/serengil/deepface_models/releases/download/v1.0/facial_expression_model_weights.h5\n","To: /root/.deepface/weights/facial_expression_model_weights.h5\n","\n","100%|██████████| 5.98M/5.98M [00:00<00:00, 152MB/s]\n","Processando vídeo: 100%|██████████| 3326/3326 [06:41<00:00,  8.28it/s]"]},{"output_type":"stream","name":"stdout","text":["Relatório salvo em: relatorio_analise_video.json\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]}]}